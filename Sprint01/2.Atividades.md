 # Sprint 01 
## Desafios:
&nbsp;&nbsp;&nbsp;Após finalizar os cursos havia dois desafios para serem feitos. Um sobre criar uma conta no GitHub, adicionar um diretório do estágio, e criar repositórios no projeto adicionando a ele o conteúdo visto ao longo das Sprints. <p>
&nbsp;&nbsp;&nbsp; E o outro desafio, agora sobre Linux, era sobre criar dois Scripts executaveis, um que executa com agendamento (de segunda a quinta, as 15h27m) e o outro manualmente. 
<p>
<p>

### Desafio Linux:
&nbsp;&nbsp;&nbsp;O Script que executa com agendamento tem o nome processamento_de_dados.sh. Ele gera dois diretórios, um chamado _vendas_ e o outro _backup_ (_bakcup_ gerado dentro de _vendas_). Copia o arquivo **dados_de_vendas.csv** de outro diretório, chamado _ecommerce_, para o diretório _vendas_ e para o diretório _backup_. Em _backup_, copia **dados_de_vendas.csv** para o arquivo criado **dados-de-vendas-yyyy/mm/dd.csv** e renomeia **dados-de-vendas-yyyy/mm/dd.csv** para **backup-dados-de-vendas-yyyy/mm/dd.csv**. <p>
&nbsp;&nbsp;&nbsp;Depois de toda esse estruturação ele gera um arquivo **relatorio.txt** (criado dentro de _backup_) que contém infomações expecíficas, como a data e hora que as informações foram geradas, data da primeira e da ultima compra, contidas no arquivo **backup-dados-de-vendas-yyyy/mm/dd.csv**, qual a quantidade total de itens vendidos, e os dez primeiros itens do arquivo **backup-dados-de-vendas-yyyy/mm/dd.csv**. Após terminar de gerar o arquivo **relatorio.txt**, o script campacta **backup-dados-de-vendas-yyyy/mm/dd.csv** e o apaga (o arquivo não compactado). Apaga também o aquivo **dados_de_vendas.csv** de _vendas_. <p>
&nbsp;&nbsp;&nbsp;Script de processamento_de_dados.sh e terminal com três relatórios criados:
<p>
<img src=../imgs/Script_processamento_de_vendas.png width=300>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   <img src=../imgs/antes_de_gerar_relatorio_fina.png width=350>
<p>
&nbsp;&nbsp;&nbsp;O Script sem agendamento, consolidador_de_processamento_de_vendas.sh, tem a ordem de criar um arquivo chamado **relatorio_fina.txt** e adicionar nele, a cada três execuções de processamento_de_dados.sh, os dados gerados no arquivo **relatorio.txt**. 
<p>
&nbsp;&nbsp;&nbsp;Script de consolidador_processamento_de_dados.sh e terminal após gerar o relatório final:
<p>
<img src=../imgs/Script_consolidador_de_processamento_de_vendas.png width=350> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src=../imgs/gerando_relatorio_fina.png width=300>
<p>
<p>
<p>
&nbsp;&nbsp;&nbsp;Visualização de parte do relatório final no terminal:
<p>
<img src=../imgs/cat-de-relatorio_fina.png width=350>