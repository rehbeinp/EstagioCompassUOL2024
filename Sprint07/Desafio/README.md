# Sprint 07
## Desafio final - Parte 02
&nbsp;&nbsp;&nbsp; O desafio foi formado pela ingestão dos dados via chamada de API realizada no AWS Lambda.<p>
&nbsp;&nbsp;&nbsp; Enfrentei algumas dificuldades e receios em fazer essa atividade, por nunca ter feito uma chamada de API. Assim optei por fazer uma que não fosse me trazer mais dificuldades e ingeri os genêros dos filmes e seus IDs. Por ser uma chamada muito básica já espero ter que fazer talvez outra chamada, em outra Sprint, para complementar os dados. Sei que não é o mais indicado deixar o problema aparecer para resolve-lo, mas no momento não sei qual informação buscar para complementar os dados para a pesquisa que desejo fazer, pois ao meu ver, os dados ingeridos na primeira parte do desafio ja seriam o suficiente para isso. Sendo assim, segue a explicação da segunda parte do desafio final.

* Primeira parte: Era necessário fazer a ingestão dos dados via chamada de API, sendo o DataBase TMBD o indicado. Após fazer login no site e entender como funcionava, fui para a confecção do código que usaria no lambda. Ao ver o que o [codigo.py](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/lambda_codigo.py)  funcionava em minha máquina, e que gerou os dados que queria ([generos_filmes.json](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/api_resultado_genero_filmes.json)), tentei aplicá-lo no lambda, o que gerou um erro, por não ter a biblioteca necessária no lambda.
* Segunda parte: Assim, sem as bibliotecas no lambda era necessário criar uma Layer para a função. Essa Layer foi criada a partir do exemplo de um exercício da Sprint anterior. Ou seja, criei um container no docker a partir do [Dockerfile](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/Dockerfile), sendo a base uma imagem AmazonLinux, que teve o python 3.9 e o pip instalados. Após isso eu realizei, a partir de [comandos no terminal](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/layer_codigo_docker.txt), a criação de um diretório layer_dir, dentro de layer_dir a criação do dirtório python, e dentro de python ocorreu a instalação da biblioteca requests. Depois de fazer a instalação necessária compactei o diretório python em um arquivo chamado [layer_requests.zip](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/layer_request.zip) e copiei o arquivo para a minha máquina local. Com a camada pronta apliquei ela diretamente na função lambda, pois ela tinha um tamanho suportado pela fução.
* Terceira parte: Com a camada adicionada parecia que estava tudo certo para funcionar, mas então ocorreu um problema de autorização, a minha função lambda não estava autorizada a acessar o bucket do S3. Assim, após realizar algumas pesquisas, resolvi esse problema adicionando uma permição de S3fullacess diretamente na função lambda, que me permitiu adicionar o objeto ([nome_objetos.txt](https://github.com/rehbeinp/EstagioC_UOL/blob/main/Sprint07/Evid%C3%AAncias/nome_objetos.txt)) ao bucket.
